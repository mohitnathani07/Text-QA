{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:45:05.660160Z",
     "iopub.status.busy": "2024-11-14T23:45:05.659748Z",
     "iopub.status.idle": "2024-11-14T23:45:05.760888Z",
     "shell.execute_reply": "2024-11-14T23:45:05.759929Z",
     "shell.execute_reply.started": "2024-11-14T23:45:05.660123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login('YOUR LOGIN KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-14T23:43:21.739218Z",
     "iopub.status.busy": "2024-11-14T23:43:21.738878Z",
     "iopub.status.idle": "2024-11-14T23:43:42.433778Z",
     "shell.execute_reply": "2024-11-14T23:43:42.432780Z",
     "shell.execute_reply.started": "2024-11-14T23:43:21.739182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:43:42.436139Z",
     "iopub.status.busy": "2024-11-14T23:43:42.435479Z",
     "iopub.status.idle": "2024-11-14T23:43:42.816436Z",
     "shell.execute_reply": "2024-11-14T23:43:42.815442Z",
     "shell.execute_reply.started": "2024-11-14T23:43:42.436101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "api_key = 'YOUR API KEY'  # Replace with your actual API key\n",
    "pinecone_client = Pinecone(api_key=api_key)\n",
    "\n",
    "# Create or connect to a specific index\n",
    "index_name = 'vector-nitor'  # Replace with your desired index name\n",
    "if index_name not in pinecone_client.list_indexes().names():\n",
    "    pinecone_client.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # 384 is the dimension for 'all-MiniLM-L6-v2' embeddings\n",
    "        metric='cosine',  # Choose an appropriate metric for similarity\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'  # Adjust the region as needed\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pinecone_client.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:44:21.199205Z",
     "iopub.status.busy": "2024-11-14T23:44:21.198829Z",
     "iopub.status.idle": "2024-11-14T23:44:25.604725Z",
     "shell.execute_reply": "2024-11-14T23:44:25.603822Z",
     "shell.execute_reply.started": "2024-11-14T23:44:21.199171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2b31ad1d434ba5ad1f43dbdd35245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b9bf1efb1b44d5bb9c039b5c787bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a46eb40da24ac5b506e8f749402337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2282141b590f40d3b23b0763d7dd34c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37123c573c54a02bf1720bd50820a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6089a9a5cc44ef2a7a3281ce5feb561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaa7c30eab4463797d72346b2f78f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a61429f199c488fad58ffb11e29c4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c26a4d8e724872b9dcef7442067db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaab94b350b40338b9290280559d7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cfd0ab385d4bf3a3ec915eaf872fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:45:11.326388Z",
     "iopub.status.busy": "2024-11-14T23:45:11.325474Z",
     "iopub.status.idle": "2024-11-14T23:47:50.127909Z",
     "shell.execute_reply": "2024-11-14T23:47:50.127063Z",
     "shell.execute_reply.started": "2024-11-14T23:45:11.326346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867ecc559cfc45008677daad977f10f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6f039caf294bc9bd86b7a2a49f9db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a559c5b4f664ae28859235bd816fff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0f2acf9e1c4135a42e269d3ea3febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f23e45b878455d85bdce94a79fc410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4a72dc785144b09185fcb10af91cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b6877bb1534334a0b0ff640eef81dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc908b8705947ea8515c3ffd81e6f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e26d511e2fe465dbaf36e0960531a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b048dcaf10d4ac28bf925c1ba00857b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "llama_pipeline =transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:48:55.511598Z",
     "iopub.status.busy": "2024-11-14T23:48:55.511157Z",
     "iopub.status.idle": "2024-11-14T23:48:55.519014Z",
     "shell.execute_reply": "2024-11-14T23:48:55.518015Z",
     "shell.execute_reply.started": "2024-11-14T23:48:55.511545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_query_embedding(query):\n",
    "    \"\"\"Generate an embedding for the user query.\"\"\"\n",
    "    return embedding_model.encode(query).tolist()\n",
    "\n",
    "def retrieve_relevant_chunks(query_embedding, top_k=5):\n",
    "    \"\"\"Retrieve top-k relevant chunks from Pinecone based on query embedding and extract only the text.\"\"\"\n",
    "    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
    "    # Extract only the 'text' field from the metadata of each match\n",
    "    relevant_texts = [match['metadata']['text'] for match in results['matches'] if 'text' in match['metadata']]\n",
    "    return relevant_texts\n",
    "\n",
    "\n",
    "def construct_prompt(relevant_chunks, query):\n",
    "    \"\"\"Construct a prompt for LLaMA model based on retrieved chunks.\"\"\"\n",
    "    text = \"\\n\\n\".join(relevant_chunks)\n",
    "    context= f\"Context:\\n{text}\"\n",
    "    prompt=\"Generate answer according to the given context for the query: \"+ query\n",
    "    return prompt, context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T00:11:48.165502Z",
     "iopub.status.busy": "2024-11-15T00:11:48.164300Z",
     "iopub.status.idle": "2024-11-15T00:11:59.285253Z",
     "shell.execute_reply": "2024-11-15T00:11:59.284259Z",
     "shell.execute_reply.started": "2024-11-15T00:11:48.165455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fd514623ca4530afe72f86d51e2c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: The diagnostic criteria for confirming a case of Diabetes Mellitus are:\n",
      "\n",
      "1. Fasting plasma glucose (FPG) ≥ 126 mg/dl\n",
      "2. Random plasma glucose (RPG) ≥ 200 mg/dl with symptoms of diabetes (polyuria, polydipsia, ketoacidosis, or unexplained weight loss)\n",
      "3. Two-hour plasma glucose (2hPG) ≥ 200 mg/dl following a 75g glucose load or 1.75g/kg body weight in children\n",
      "\n",
      "These criteria are used to confirm a diagnosis of diabetes mellitus, with the understanding that a single abnormal result may not be sufficient to make a definitive diagnosis. The diagnosis is typically confirmed by repeating the test, and the results must meet the above criteria to be considered a confirmed case of diabetes mellitus.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_answer_from_llama(prompt,context):\n",
    "    \"\"\"Generate response using the LLaMA pipeline with formatted messages.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": context},\n",
    "    ]\n",
    "    outputs = llama_pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        )\n",
    "    return outputs[0]['generated_text'][-1]['content']  # Clean up any leading/trailing whitespace\n",
    "\n",
    "def respond_to_query(query):\n",
    "    \"\"\"End-to-end RAG pipeline to respond to user query.\"\"\"\n",
    "    query_embedding = generate_query_embedding(query)\n",
    "    relevant_chunks = retrieve_relevant_chunks(query_embedding)\n",
    "    prompt,context = construct_prompt(relevant_chunks, query)\n",
    "    answer = get_answer_from_llama(prompt, context)\n",
    "    return context,answer\n",
    "\n",
    "# Example usage\n",
    "# user_query = \"What are the diagnostic criteria for confirming a case of Diabetes Mellitus?\"\n",
    "# context,response = respond_to_query(user_query)\n",
    "# print(\"Generated Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T00:06:55.925634Z",
     "iopub.status.busy": "2024-11-15T00:06:55.925253Z",
     "iopub.status.idle": "2024-11-15T00:06:55.931674Z",
     "shell.execute_reply": "2024-11-15T00:06:55.930700Z",
     "shell.execute_reply.started": "2024-11-15T00:06:55.925597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The key symptoms that indicate a possible case of Type 1 Diabetes in children and young adults are:\\n\\n1. Fever\\n2. Pain abdomen\\n3. Polyuria (excessive urination)\\n4. Weight loss\\n\\nThese symptoms are often mistaken for an acute infective illness in children, but they can be a sign of Type 1 Diabetes. Type 1 Diabetes is an autoimmune condition that destroys the insulin-producing beta cells in the pancreas, leading to a complete lack of insulin production and a requirement for insulin therapy.\\n\\nIt's essential to suspect and diagnose Type 1 Diabetes early, as it can lead to severe complications if left untreated. If you suspect a child or young adult has Type 1 Diabetes, it's crucial to seek medical attention and refer them to a higher-level facility for further evaluation and treatment.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T00:13:56.465961Z",
     "iopub.status.busy": "2024-11-15T00:13:56.465534Z",
     "iopub.status.idle": "2024-11-15T00:13:56.471746Z",
     "shell.execute_reply": "2024-11-15T00:13:56.470620Z",
     "shell.execute_reply.started": "2024-11-15T00:13:56.465922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpt_res='''Diabetes Mellitus is diagnosed primarily through blood glucose tests. The criteria include:\n",
    "\n",
    "Fasting Plasma Glucose (FPG): A blood test after at least 8 hours of fasting. A reading of ≥126 mg/dL (7.0 mmol/L) indicates diabetes.\n",
    "\n",
    "Oral Glucose Tolerance Test (OGTT): Measures blood glucose two hours after consuming a glucose-rich drink. A reading of ≥200 mg/dL (11.1 mmol/L) confirms diabetes.\n",
    "\n",
    "Random Plasma Glucose Test: Used when symptoms (e.g., polyuria, polydipsia) are present. A level of ≥200 mg/dL (11.1 mmol/L) indicates diabetes.\n",
    "\n",
    "Hemoglobin A1c (HbA1c): Reflects average blood glucose over three months. An HbA1c level ≥6.5% confirms diabetes. For accuracy, HbA1c tests should be performed in a standardized lab.\n",
    "\n",
    "If results fall within prediabetes ranges, further testing or lifestyle intervention may be recommended.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T00:14:03.216182Z",
     "iopub.status.busy": "2024-11-15T00:14:03.215519Z",
     "iopub.status.idle": "2024-11-15T00:14:03.225846Z",
     "shell.execute_reply": "2024-11-15T00:14:03.224966Z",
     "shell.execute_reply.started": "2024-11-15T00:14:03.216141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.4358697266297498\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluation_matrics(response, context):\n",
    "  bleu_score = sentence_bleu([context], response)\n",
    "  response_vector = model.encode(response)\n",
    "  context_vector = model.encode(context)\n",
    "  response_vector = response_vector.reshape(1, -1)\n",
    "  context_vector = context_vector.reshape(1, -1)\n",
    "  similarity = cosine_similarity(response_vector, context_vector)\n",
    "  print(bleu_score,similarity[0][0])\n",
    "  return bleu_score, similarity[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def run(query):\n",
    "  context, answer = respond_to_query(query)\n",
    "  print(answer,prompt)\n",
    "  bleu, similarity = evaluation_matrics(answer, concat_result)\n",
    "  print(bleu,similarity)\n",
    "  return answer\n",
    "\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=run,\n",
    "    inputs=[\"text\"],\n",
    "    outputs=[\"text\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
