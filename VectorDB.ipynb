{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0JA-NX0E8Dza"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zYf1UGD7CJn"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login('YOUR LOGIN KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hn4ZMvUl1lgQ"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "IlrPdXDaAg3k",
    "outputId": "d742af10-30b8-45ae-b6c1-af4ec64d5042"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cbfb97c97137>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Split the text into sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(?<=[.!?]) +'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Generate chunks with overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define parameters\n",
    "chunk_size = 10 # Number of sentences per chunk\n",
    "overlap_percent = 0.2  # 20% overlap\n",
    "overlap_size = int(chunk_size * overlap_percent)\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "\n",
    "# Generate chunks with overlap\n",
    "chunks = []\n",
    "start = 0\n",
    "while start < len(sentences):\n",
    "    end = start + chunk_size\n",
    "    chunk = \" \".join(sentences[start:end])\n",
    "    chunks.append(chunk)\n",
    "    start += chunk_size - overlap_size  # Move start by chunk size minus overlap\n",
    "\n",
    "# Output chunk count and example chunk\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "print(\"Example chunk:\", chunks[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqgfmsu912F6",
    "outputId": "3b1191fb-ced8-4df2-9dda-f109f07004d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Download sentence tokenizer data if not already installed\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize SpaCy for NLP\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Load a sentence embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-bDMnOABLCO",
    "outputId": "c566df72-c61e-4335-f7ff-2440e9f8b2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings created: 10\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Generate embeddings for each chunk and store them in the list\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Generate the embedding vector for each chunk\n",
    "    embedding = embedder.encode(chunk).tolist()\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Now `embeddings` is a list of all chunk embeddings\n",
    "print(f\"Total embeddings created: {len(embeddings)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vk-1v_y5-2n"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "api_key = 'YOUR API KEY'  # Replace with your actual API key\n",
    "pinecone_client = Pinecone(api_key=api_key)\n",
    "\n",
    "# Create or connect to a specific index\n",
    "index_name = 'vector-nitor'  # Replace with your desired index name\n",
    "if index_name not in pinecone_client.list_indexes().names():\n",
    "    pinecone_client.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # 384 is the dimension for 'all-MiniLM-L6-v2' embeddings\n",
    "        metric='cosine',  # Choose an appropriate metric for similarity\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'  # Adjust the region as needed\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pinecone_client.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u5VYlPV89_d",
    "outputId": "9d03ba20-6705-4868-d6eb-c01530dee3aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion into Pinecone complete.\n"
     ]
    }
   ],
   "source": [
    "vectors = [(str(i), embeddings[i], {\"text\": chunks[i]}) for i in range(len(embeddings))]\n",
    "\n",
    "# Insert data into Pinecone\n",
    "index.upsert(vectors)\n",
    "\n",
    "print(\"Data ingestion into Pinecone complete.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
